{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hugging Face x LangChain : A new partner package in LangChain\n",
    "langchain_huggingface, a partner package in LangChain jointly maintained by Hugging Face and LangChain. This new Python package is designed to bring the power of the latest development of Hugging Face into LangChain and keep it up to date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.26.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.3.21)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain_huggingface) (3.3.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain_huggingface) (0.20.3)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain_huggingface) (4.46.3)\n",
      "Requirement already satisfied: filelock in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.1.146)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.0.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.2)\n",
      "Requirement already satisfied: scipy in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n",
      "Requirement already satisfied: Pillow in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
      "Requirement already satisfied: anyio in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (0.26.2)\n",
      "Requirement already satisfied: filelock in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mahmoodinamdar/Downloads/Projects/venv/lib/python3.12/site-packages (from requests->huggingface_hub) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFaceEndpoint\n",
    "#### How to Access HuggingFace Models with API\n",
    "There are also two ways to use this class. You can specify the model with the repo_id parameter. Those endpoints use the serverless API, which is particularly beneficial to people using pro accounts or enterprise hub. Still, regular users can already have access to a fair amount of request by connecting with their HF token in the environment where they are executing the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?\\n\\nMachine learning (ML) is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed.\\n\\nMachine learning focuses on the development of computer programs that can access data and use it to learn for themselves. The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future based on the examples that we provide. The primary aim is to allow the computers to learn automatically without human intervention or assistance and adjust actions accordingly.\\n\\nThere are three main types of machine learning:\\n\\n- Supervised learning: The algorithm is provided with labeled data, such as images of cats and dogs, and learns to classify new data based on what it has been taught.\\n- Unsupervised learning: The algorithm is provided with unlabeled data, such as customer data, and learns to identify patterns or relationships in the data.\\n- Reinforcement learning: The algorithm learns to make decisions by taking actions in an environment to achieve a goal, such as playing a game, and receiving feedback in the form of rewards or punishments.\\n\\nMachine learning is used in a wide range of applications, including image and speech recognition, natural language processing, recommendation systems, and fraud detection. It is also used in autonomous vehicles, predictive maintenance, and personalized medicine.\\n\\nMachine learning algorithms are trained on large datasets and use mathematical and statistical models to make predictions or decisions without being explicitly programmed to perform the task. The algorithms can learn from data and improve their performance over time as they are exposed to more data.\\n\\nMachine learning is a powerful tool that can help organizations make better decisions, improve efficiency, and gain insights from their data. It is a rapidly growing field, with new techniques and applications being developed all the time.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='google/gemma-2-9b', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='google/gemma-2-9b', client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>, async_client=<InferenceClient(model='google/gemma-2-9b', timeout=120)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"google/gemma-2-9b\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "HfHubHTTPError",
     "evalue": "(Request ID: 0mjGsNvNPiIJO1SsTFHRQ)\n\n403 Forbidden: None.\nCannot access content at: https://api-inference.huggingface.co/models/google/gemma-2-9b.\nMake sure your token has the correct permissions.\nThe model google/gemma-2-9b is too large to be loaded automatically (36GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://api-inference.huggingface.co/models/google/gemma-2-9b",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat is machine learning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:390\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    387\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    388\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    402\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:755\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    749\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    754\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:950\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    937\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    938\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    948\u001b[0m         )\n\u001b[1;32m    949\u001b[0m     ]\n\u001b[0;32m--> 950\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:792\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    790\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    791\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 792\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    793\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    794\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:779\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    771\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    776\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 779\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    783\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    787\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    788\u001b[0m         )\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_core/language_models/llms.py:1502\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1501\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1502\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1503\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1504\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1505\u001b[0m     )\n\u001b[1;32m   1506\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/langchain_huggingface/llms/huggingface_endpoint.py:312\u001b[0m, in \u001b[0;36mHuggingFaceEndpoint._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     invocation_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m invocation_params[\n\u001b[1;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop_sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m     ]  \u001b[38;5;66;03m# porting 'stop_sequences' into the 'stop' argument\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minvocation_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m     response_text \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# Maybe the generation has stopped at one of the stop sequences:\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# then we remove this stop sequence from the end of the generated text\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/huggingface_hub/inference/_client.py:296\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 296\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[0;32m~/Downloads/Projects/venv/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:468\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    463\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure your token has the correct permissions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     )\n\u001b[0;32m--> 468\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m416\u001b[39m:\n\u001b[1;32m    471\u001b[0m     range_header \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRange\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mHfHubHTTPError\u001b[0m: (Request ID: 0mjGsNvNPiIJO1SsTFHRQ)\n\n403 Forbidden: None.\nCannot access content at: https://api-inference.huggingface.co/models/google/gemma-2-9b.\nMake sure your token has the correct permissions.\nThe model google/gemma-2-9b is too large to be loaded automatically (36GB > 10GB). Please use Spaces (https://huggingface.co/spaces) or Inference Endpoints (https://huggingface.co/inference-endpoints)."
     ]
    }
   ],
   "source": [
    "llm.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.3', temperature=0.7, stop_sequences=[], server_kwargs={}, model_kwargs={'max_length': 150, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.3', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.3', timeout=120)>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=150,temperature=0.7,token=os.getenv(\"HF_TOKEN\"))\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] input_types={} partial_variables={} template='\\nQuestion:{question}\\nAnswer: Lets think step by step.\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate,LLMChain\n",
    "\n",
    "template=\"\"\"\n",
    "Question:{question}\n",
    "Answer: Lets think step by step.\n",
    "\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template,input_variables=[\"question\"])\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l2/pmkyw7ps4898zb_sy_4ldz3r0000gn/T/ipykernel_7333/1587741202.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm,prompt=prompt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nIndia won the Cricket World Cup 2021. The final match was held on 14th July 2021 between India and New Zealand at the Lord's cricket ground in London, England. India won the match by 8 wickets.\\n\\nIndia chased down the target of 240 runs in 40.1 overs, with Rishabh Pant being the hero of the match by scoring an unbeaten 84 runs off 45 balls.\\n\\nThis was India's third World Cup title, and they joined Australia as the only team to have won the World Cup three times.\\n\\nThe man of the match was Trent Boult of New Zealand, who took 3 wickets for 27 runs. The man of the series was Kane Williamson of New Zealand, who scored 578 runs in the tournament, including a century in the final.\\n\\nThe final match was a thrilling one, with both teams showing great determination and skill. It was a fitting end to a tournament that saw some exciting and close matches throughout.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(llm=llm,prompt=prompt)\n",
    "llm.invoke(\"Who won the cricket world cup 2021?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en\"\n",
    "model_kwargs = {\"device\": \"cpu\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = hf.embed_query(\"hi this is harrison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.028416570276021957,\n",
       " 0.01218326110392809,\n",
       " 0.02744395285844803,\n",
       " -0.05482868477702141,\n",
       " 0.024238895624876022,\n",
       " 0.0007663027499802411,\n",
       " 0.06783367693424225,\n",
       " 0.016348330304026604,\n",
       " -0.018950726836919785,\n",
       " 0.012542902491986752,\n",
       " 0.021565012633800507,\n",
       " -0.08793040364980698,\n",
       " 0.0006460626609623432,\n",
       " 0.03327081352472305,\n",
       " 0.005463769193738699,\n",
       " -0.060376446694135666,\n",
       " 0.05042264983057976,\n",
       " 0.004434812813997269,\n",
       " 0.0009598906617611647,\n",
       " 0.001740555395372212,\n",
       " 0.003298819065093994,\n",
       " 0.03167251497507095,\n",
       " -0.04880748316645622,\n",
       " -0.044819168746471405,\n",
       " 0.07132109999656677,\n",
       " -0.007510861847549677,\n",
       " -0.0011259387247264385,\n",
       " -0.01580117642879486,\n",
       " -0.029402390122413635,\n",
       " -0.17224569618701935,\n",
       " -0.03189521282911301,\n",
       " -0.0016291557112708688,\n",
       " 0.018105000257492065,\n",
       " 0.015315389260649681,\n",
       " -0.02072960138320923,\n",
       " -0.008872968144714832,\n",
       " -0.0012822606367990375,\n",
       " 0.02727687917649746,\n",
       " -0.010114257223904133,\n",
       " 0.012621627189218998,\n",
       " -0.007077888119965792,\n",
       " -0.016693176701664925,\n",
       " 0.04085584729909897,\n",
       " 0.023938359692692757,\n",
       " -0.020081529393792152,\n",
       " 0.028681166470050812,\n",
       " -0.019400743767619133,\n",
       " -0.01461822260171175,\n",
       " 0.017379598692059517,\n",
       " 0.004164116457104683,\n",
       " 0.06415649503469467,\n",
       " 0.04768306016921997,\n",
       " 0.0018365108408033848,\n",
       " -8.069891191553324e-05,\n",
       " 0.016596784815192223,\n",
       " 0.01112417597323656,\n",
       " 0.069694384932518,\n",
       " 0.05182051286101341,\n",
       " 0.055685292929410934,\n",
       " 0.05551541969180107,\n",
       " 0.000503954419400543,\n",
       " 0.0418705940246582,\n",
       " -0.15344089269638062,\n",
       " 0.05180780589580536,\n",
       " 0.006689767353236675,\n",
       " -0.031670719385147095,\n",
       " -0.00910499319434166,\n",
       " -0.05160471796989441,\n",
       " 0.042508576065301895,\n",
       " 0.028200050815939903,\n",
       " -0.010748122818768024,\n",
       " 0.02240579202771187,\n",
       " 0.044395506381988525,\n",
       " 0.004115506075322628,\n",
       " 0.018998470157384872,\n",
       " -0.0043571749702095985,\n",
       " 0.047627635300159454,\n",
       " 0.011824624612927437,\n",
       " 0.008164589293301105,\n",
       " 0.008177286945283413,\n",
       " -0.009698748588562012,\n",
       " -0.014260281808674335,\n",
       " 0.01140968780964613,\n",
       " -0.07362118363380432,\n",
       " -0.05439520627260208,\n",
       " -0.05703963711857796,\n",
       " -0.0036085559986531734,\n",
       " 0.0026660740841180086,\n",
       " 0.02378246560692787,\n",
       " 0.015376233495771885,\n",
       " -0.07020371407270432,\n",
       " -0.03130035847425461,\n",
       " -0.0031142844818532467,\n",
       " -0.01581217162311077,\n",
       " -0.03791400417685509,\n",
       " -0.025921903550624847,\n",
       " 0.018168391659855843,\n",
       " -0.03882461041212082,\n",
       " -0.05674504116177559,\n",
       " 0.5792060494422913,\n",
       " -0.052788347005844116,\n",
       " 0.020716402679681778,\n",
       " 0.06794389337301254,\n",
       " -0.045416515320539474,\n",
       " 0.011642496101558208,\n",
       " -0.021571775898337364,\n",
       " 0.020341746509075165,\n",
       " -0.02744893915951252,\n",
       " -0.045588940382003784,\n",
       " -0.029443563893437386,\n",
       " -0.02366250939667225,\n",
       " -0.03431524336338043,\n",
       " 0.0019388552755117416,\n",
       " -0.07095138728618622,\n",
       " 0.0345563180744648,\n",
       " -0.03055897168815136,\n",
       " 0.03907858580350876,\n",
       " -0.02970731258392334,\n",
       " -0.0008282869821414351,\n",
       " -0.012159367091953754,\n",
       " -0.018272830173373222,\n",
       " 0.025486500933766365,\n",
       " -0.00446167541667819,\n",
       " 0.016335325315594673,\n",
       " 0.019126489758491516,\n",
       " -0.054832059890031815,\n",
       " 0.027635985985398293,\n",
       " -0.004757677670568228,\n",
       " 0.059001725167036057,\n",
       " -0.0016944598173722625,\n",
       " 0.008015020750463009,\n",
       " -0.037726860493421555,\n",
       " -0.09893043339252472,\n",
       " -0.022574400529265404,\n",
       " -0.03760465234518051,\n",
       " -0.0021698703058063984,\n",
       " 0.0032445956021547318,\n",
       " -0.01920252852141857,\n",
       " -0.00863123033195734,\n",
       " -0.048023078590631485,\n",
       " 0.00869669672101736,\n",
       " -0.09516110271215439,\n",
       " -0.03496047854423523,\n",
       " -0.043607987463474274,\n",
       " -0.00034400622826069593,\n",
       " -0.010173656046390533,\n",
       " -0.03099953569471836,\n",
       " 0.024309685453772545,\n",
       " -0.02040201611816883,\n",
       " 0.03113938495516777,\n",
       " 0.0008811301086097956,\n",
       " 0.013916472904384136,\n",
       " -0.03119621053338051,\n",
       " -0.037154048681259155,\n",
       " 0.004029625095427036,\n",
       " 0.014799803495407104,\n",
       " 0.043188951909542084,\n",
       " 0.03875482454895973,\n",
       " 0.013851995579898357,\n",
       " 0.019797876477241516,\n",
       " 0.010267077013850212,\n",
       " -0.005434128921478987,\n",
       " -0.014299212023615837,\n",
       " 0.027637850493192673,\n",
       " 0.009802650660276413,\n",
       " -0.1355028748512268,\n",
       " -0.017139777541160583,\n",
       " 0.0176171213388443,\n",
       " 0.023132245987653732,\n",
       " 0.0017590075731277466,\n",
       " 0.030889403074979782,\n",
       " 0.03991870582103729,\n",
       " -0.013684174045920372,\n",
       " 0.024816513061523438,\n",
       " 0.054050177335739136,\n",
       " 0.017761144787073135,\n",
       " -0.018475055694580078,\n",
       " 0.02595539204776287,\n",
       " -0.006377531681209803,\n",
       " -0.016587331891059875,\n",
       " 0.037848033010959625,\n",
       " -0.027290044352412224,\n",
       " -0.0528457947075367,\n",
       " -0.03803316131234169,\n",
       " 0.051911044865846634,\n",
       " -0.007557070814073086,\n",
       " -0.03180530294775963,\n",
       " 0.013284198008477688,\n",
       " -0.027723725885152817,\n",
       " 0.05630653724074364,\n",
       " 0.00304190325550735,\n",
       " 0.053324855864048004,\n",
       " -0.05791123956441879,\n",
       " -0.011325804516673088,\n",
       " -0.031172022223472595,\n",
       " 0.025608692318201065,\n",
       " 0.03389061614871025,\n",
       " -0.0010284552117809653,\n",
       " 0.01586487889289856,\n",
       " 0.010595209896564484,\n",
       " -0.02703780308365822,\n",
       " -0.000930823793169111,\n",
       " -0.04815223813056946,\n",
       " 0.02817925252020359,\n",
       " 0.010320620611310005,\n",
       " 0.06662961095571518,\n",
       " -0.016558198258280754,\n",
       " -0.004431365989148617,\n",
       " 0.038234248757362366,\n",
       " -0.023408209905028343,\n",
       " -0.03558176010847092,\n",
       " -0.058290719985961914,\n",
       " -0.011181486770510674,\n",
       " -0.017684558406472206,\n",
       " -0.016141291707754135,\n",
       " -0.03424530848860741,\n",
       " -0.02513955533504486,\n",
       " 0.03939665108919144,\n",
       " -0.023658212274312973,\n",
       " -0.007725011091679335,\n",
       " -0.0050989012233912945,\n",
       " -0.03523435816168785,\n",
       " -0.014076832681894302,\n",
       " -0.223260298371315,\n",
       " -0.031471382826566696,\n",
       " -0.001290609478019178,\n",
       " -0.0017199995927512646,\n",
       " -0.007846043445169926,\n",
       " -0.058023229241371155,\n",
       " 0.04617457836866379,\n",
       " 0.024552667513489723,\n",
       " 0.07320841401815414,\n",
       " 0.017268329858779907,\n",
       " 0.047612063586711884,\n",
       " 0.013473291881382465,\n",
       " -0.005516032688319683,\n",
       " -0.01435785461217165,\n",
       " -0.009674306958913803,\n",
       " 0.04878249391913414,\n",
       " 0.03053811565041542,\n",
       " -0.024993956089019775,\n",
       " 0.021486200392246246,\n",
       " 0.017639808356761932,\n",
       " 0.053138915449380875,\n",
       " 0.013485017232596874,\n",
       " -0.023225976154208183,\n",
       " -0.021403977647423744,\n",
       " 0.026075342670083046,\n",
       " 0.00202918634749949,\n",
       " 0.12753742933273315,\n",
       " 0.0831683874130249,\n",
       " 0.04408949986100197,\n",
       " -0.02670358121395111,\n",
       " 0.005522002466022968,\n",
       " -0.009294887073338032,\n",
       " 0.02007431350648403,\n",
       " -0.09684176743030548,\n",
       " -0.024703949689865112,\n",
       " 0.025086980313062668,\n",
       " 0.0020886200945824385,\n",
       " -0.04489403963088989,\n",
       " -0.07861138880252838,\n",
       " -0.0043763406574726105,\n",
       " -0.06590454280376434,\n",
       " 0.014689415693283081,\n",
       " -0.05764184892177582,\n",
       " -0.07152026146650314,\n",
       " -0.06232650578022003,\n",
       " 0.0034316531382501125,\n",
       " -0.046065520495176315,\n",
       " 0.045300886034965515,\n",
       " -0.026762282475829124,\n",
       " 0.03401092067360878,\n",
       " 0.04547379910945892,\n",
       " -0.02817925252020359,\n",
       " 0.005011805798858404,\n",
       " 0.00963085237890482,\n",
       " -0.030305583029985428,\n",
       " -0.036124810576438904,\n",
       " -0.013626969419419765,\n",
       " -0.03265371546149254,\n",
       " -0.04467753320932388,\n",
       " 0.010642178356647491,\n",
       " -0.027486367151141167,\n",
       " -0.024565119296312332,\n",
       " -0.024747759103775024,\n",
       " 0.05361958220601082,\n",
       " 0.020789965987205505,\n",
       " 0.019468480721116066,\n",
       " 0.053241197019815445,\n",
       " -0.014002456329762936,\n",
       " 0.021243255585432053,\n",
       " -0.04957323521375656,\n",
       " -0.008522579446434975,\n",
       " 0.007852853275835514,\n",
       " -0.05719393864274025,\n",
       " -0.027550633996725082,\n",
       " 0.0053008804097771645,\n",
       " 0.04007291421294212,\n",
       " 0.01959790103137493,\n",
       " -0.045197341591119766,\n",
       " 0.0324358306825161,\n",
       " -0.012342419475317001,\n",
       " 0.034314412623643875,\n",
       " 0.021102113649249077,\n",
       " 0.03984648361802101,\n",
       " 0.031663794070482254,\n",
       " -0.033590223640203476,\n",
       " 0.031647853553295135,\n",
       " -0.0033045068848878145,\n",
       " 0.004641844425350428,\n",
       " 0.03758934140205383,\n",
       " -0.059244606643915176,\n",
       " 0.0070283678360283375,\n",
       " 0.003808695124462247,\n",
       " -0.025788873434066772,\n",
       " -0.02120334468781948,\n",
       " 0.022691236808896065,\n",
       " -0.021772967651486397,\n",
       " -0.27963775396347046,\n",
       " 0.007267436012625694,\n",
       " 0.021072017028927803,\n",
       " 0.04519747570157051,\n",
       " -0.020534461364150047,\n",
       " 0.02431372180581093,\n",
       " -0.0006137006566859782,\n",
       " -0.011857026256620884,\n",
       " -0.032967738807201385,\n",
       " 0.035843148827552795,\n",
       " 0.031281739473342896,\n",
       " 0.06373955309391022,\n",
       " 0.04654783755540848,\n",
       " -0.014470528811216354,\n",
       " 0.015869716182351112,\n",
       " 0.033971257507801056,\n",
       " 0.01805957965552807,\n",
       " 0.00229873089119792,\n",
       " 0.01654987968504429,\n",
       " -0.021714884787797928,\n",
       " -0.03485998511314392,\n",
       " -0.0008649301598779857,\n",
       " 0.15126045048236847,\n",
       " -0.024536767974495888,\n",
       " 0.030671216547489166,\n",
       " -0.00731821171939373,\n",
       " -0.006135447882115841,\n",
       " 0.06415146589279175,\n",
       " 0.0160214900970459,\n",
       " -0.03636442869901657,\n",
       " 0.019898630678653717,\n",
       " -0.02117234468460083,\n",
       " 0.04829412326216698,\n",
       " -0.044780973345041275,\n",
       " 0.04763379693031311,\n",
       " 0.0007749441429041326,\n",
       " -0.0059279389679431915,\n",
       " 0.06154269725084305,\n",
       " 0.023968394845724106,\n",
       " 0.013305009342730045,\n",
       " 0.022684503346681595,\n",
       " 0.014538073912262917,\n",
       " -0.05215905234217644,\n",
       " -0.03274965658783913,\n",
       " 0.08583344519138336,\n",
       " -0.003724820679053664,\n",
       " 0.001349432161077857,\n",
       " 0.04091988503932953,\n",
       " 0.011659679003059864,\n",
       " 0.05843617394566536,\n",
       " -0.02228616178035736,\n",
       " -0.011520704254508018,\n",
       " 0.00470571918413043,\n",
       " 0.0471826009452343,\n",
       " -0.0019179005175828934,\n",
       " 0.03300934657454491,\n",
       " -0.035050563514232635,\n",
       " -0.020736563950777054,\n",
       " -0.009222174994647503,\n",
       " 0.014618250541388988,\n",
       " 0.006456043105572462,\n",
       " 0.0010978342033922672,\n",
       " 0.010224005207419395,\n",
       " 0.08537217974662781,\n",
       " 0.03883952647447586]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
